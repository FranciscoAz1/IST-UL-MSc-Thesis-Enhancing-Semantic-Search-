% #############################################################################
% This is Chapter 1
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Introduction}
\cleardoublepage
% The following line allows to ref this chapter
\label{chap:intro}
\section{Contextual Background}
The topic of this thesis arises from the context of Edoclink, a cloud-based business management platform developed by Link Consulting.\footnote{\url{https://linkconsulting.com/what-we-do/products/edoclink-v8/}} Edoclink is designed to support organizations in managing their information in an effective, autonomous, and scalable manner, through the integration of advanced artificial intelligence techniques. The platform offers a broad range of functionalities for document management, workflow automation, and general information governance, making it increasingly feature-rich and adaptable to diverse operational needs.

The recent advancements in natural language processing (\gls{NLP}), particularly with the emergence of large language models (\glsxtrfullpl{LLM}), have introduced new paradigms in document processing. These models are capable of producing contextually rich and semantically meaningful outputs, even from unstructured data sources. As such, they enable a new class of intelligent information systems that go beyond traditional keyword-based approaches, offering enhanced information extraction, retrieval, and summarization capabilities.

Due to confidentiality constraints, the specific clients using Edoclink cannot be disclosed. Nevertheless, the work presented in this thesis is developed in a generalized context, with the aim of addressing typical challenges faced in enterprise information management. In particular, emphasis is placed on ensuring that the proposed solution is scalable in highly dynamic environments and maintains high interoperability with existing systems and standards.

% #############################################################################
\section{Motivation}

Enterprises still struggle to find the right information quickly and safely. Keyword search over heterogeneous repositories yields brittle results; users either get too little or too much, and answers are not grounded in the right documents. Recent progress in \glsxtrfull{LLM}s enables more semantic, context-aware retrieval and answering, but naïvely applying them in corporate settings collides with constraints on privacy, structure, and cost.

Modern models build on the Transformer architecture~\cite{vaswani2017attention}, which scales attention to capture long-range dependencies far beyond earlier \glsxtrfull{RNN}/\glsxtrfull{LSTM} approaches. Combined with retrieval-augmented generation (\gls{RAG})—where embeddings index content and retrieved passages ground responses—LLMs can unlock far better enterprise search experiences.

However, straightforward \gls{RAG} often falls short in practice: heterogeneous sources (mixed-quality PDFs, scans without text, inconsistent metadata) degrade indexing and recall; structure-awareness is required because many queries depend on organizational context (entity, folder, workflow), not just local text; privacy and compliance demand local data handling with auditable access aligned to \glsxtrfull{GDPR}; latency and cost constraints favor efficient local components for predictable performance; and answer quality suffers when models drift or hallucinate without strong grounding and planning.

This thesis is motivated by building a lightweight, structure-aware, and privacy-preserving \gls{RAG} stack that integrates with existing systems (e.g., Edoclink) and improves end-to-end retrieval quality with minimal operational overhead.

\subsubsection{Motivating Use Case: Procurement Delivery Acceptance}
\label{subsec:motivation-usecase}% chktex 24
Consider procurement delivery acceptance reports: routine documents that confirm receipt and acceptance of goods or services and typically include dates, quantities, and conditions. Below is a minimal vignette that illustrates the kind of precise, document-grounded answer this thesis targets.

\paragraph{Document (example).}

\begin{lstlisting}[breaklines=true]
Delivery Acceptance Report: Ergonomic Chairs (PO-4821).
Supplier: LusOffice, Lda.
Delivery note: DN-2024-146; delivery date: 2024-03-28; destination: Operations, Floor 3, Dock B.
Items: 60 ergonomic chairs (model ErgoFlex-300); one unit damaged on arrival and replaced on-site by the carrier.
Inspection: Facilities (Maria Santos, Facilities Manager).
Final acceptance recorded on 2024-03-31 after facilities sign-off.
\end{lstlisting}

\paragraph{Question.} I am looking for the ergonomic chairs delivery to Operations; did we officially accept it, when was it signed off, and by whom?

\paragraph{Gold answer.} Accepted on 2024-03-31 after facilities sign-off (Maria Santos). Source: \textit{Delivery Acceptance Report: Ergonomic Chairs (PO-4821)}

This example illustrates realistic user behavior and the kind of precise, document-grounded answer this thesis targets. It also highlights key challenges: the answer is not a verbatim excerpt but requires reasoning over multiple fields (item type, location, acceptance status, date, signatory); users may not know exact terms or document locations, so retrieval needs to be semantic and context-aware; and the answer must remain auditable and grounded in source content for compliance.

This motivates systems that intuitively retrieve the right information fast, ground answers in source content, and keep results auditable. While keyword search and structure-based navigation exist, they often depend on exact terms and prior knowledge of where content resides; a semantic, context-aware approach reduces this burden by surfacing relevant sources and grounding answers in them. This is especially helpful for non-expert users who need quick, accurate information without deep familiarity with document locations or terminology, and for users working with highly dynamic document repositories where manual organization is impractical.

\section{Objectives}
This thesis aims to design and implement a lightweight yet functional architecture for improving search and organization of information in company environments. Concretely, it targets: (i) decentralized semantic search across multiple information stores for accessibility and scalability; (ii) a complete retrieval-augmented generation (\gls{RAG}) pipeline to process and index documents, extract and persist metadata, and compute embeddings for efficient semantic retrieval; (iii) automatic metadata extraction and organization suggestions to boost search accuracy and encourage better document management; (iv) optional internet-aware search to enrich results with external sources when appropriate; and (v) an agentic, conversational search interface (chatbot) that can connect to external tools and data sources. Together, these objectives form the basis of an intuitive, robust, scalable, and cost-efficient information retrieval system tailored for dynamic distributed company environments.
% #############################################################################
\section{Organization of the Document}

\Cref{chap:back} presents the theoretical background required to understand the developed work, including fundamental concepts of information retrieval, vector representations, and large language models. 

\Cref{chap:State_of_Art} reviews the state of the art in agentic artificial intelligence, highlighting reasoning frameworks and tool-use paradigms that inspired the proposed architecture. 


In \Cref{chapter:System_Arquitecture}, the overall system architecture is detailed, describing how document processing, schema design, and retrieval components integrate into a unified solution.

\Cref{chapter:Results} reports the experimental setup, performance evaluation, and discussion of the obtained results, comparing different retrieval strategies and assessing their effectiveness. 

Finally, \Cref{chap:conclusion} concludes the dissertation by summarizing the main contributions, identifying system limitations, and outlining future research directions.
