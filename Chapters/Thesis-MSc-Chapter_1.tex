% #############################################################################
% This is Chapter 1
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Introduction}
\cleardoublepage
% The following line allows to ref this chapter
\label{chap:intro}
Edoclink is a cloud platform for business management. It aims at managing your information effectively, and autonomously. Using AI techniques. This is an increasingly feature rich platform for managing documents, business workflows, and information management.
With the rise of \acp{LLM} and other \ac{NLP} techniques offering an actually comprehensive output. Provides a new way for programs to process documents. Even in a unstructured format more effectively. Essentially providing enhanced information management.
The specific clients of Edoclink are confidential. As Edoclink ensures information confidentiality. So this thesis will focus in the general scenario of managing documents and information. While also making sure the feature is scalable in highly dynamic environments, and has easy interoperability.

% #############################################################################
\section{Motivation}

In recent years, the development of \ac{LLM}, such as ChatGPT, LLama, Gemini, etc., has marked a significant milestone in the evolution of \ac{NLP}. These models stand out for their ability to understand and generate text in natural language with high precision and context scale. These advancements were made possible by the introduction of the Transformer architecture \cite{vaswani2017attention}.

The Transformer revolutionized the field by introducing advanced self-attention mechanisms and scalability, enabled by its highly parallelizable structure. Unlike previous architectures such as \ac{RNN} and \ac{LSTM}, which rely on sequential processing, the Transformer uses multi-head attention and parallel operations to capture long-range dependencies in large datasets more efficiently. This innovation is the technological foundation of modern \ac{LLM} like ChatGPT, LLama, Gemini, etc., allowing them to handle much more complex, diverse, and large-scale contexts than sequential types.

\ac{LLM} excel not only in their ability to understand and generate text with high accuracy but also in their ability to process large volumes of information, with complex \ac{RAG} systems. That use embeddings to process text in to vectors better indexed with \ac{RAG}, making them indispensable tools for organizations looking to transform large amount of information into useful knowledge. Their implementation enables more efficient and contextualized interactions with organizational data, offering precise responses to complex queries and optimizing decision-making processes based on information.

The combined use of \ac{RAG} and \ac{LLM} represents a promising solution to overcome these challenges. Models like ChatGPT and LLama which can be embedded with \ac{RAG} have demonstrated high performance in the contextualized retrieval of information and responding to complex queries. However, implementing these models in a corporate context requires a customized approach that respects information privacy and confidentiality, integration with existing organized information, and is scalable to meet the specific needs of each client. Additionally, it is necessary to ensure that the models can operate efficiently in local environments, ensuring that security and compliance with regulations, such as \ac{GDPR}, are fully met.


% #############################################################################
\section{Organization of the Document}
This thesis is is organized as follows: \Cref{chap:intro} \todo[color=cyan!40, author=RC, fancyline]{references to doc sections/chapters are automatic}{}interdum vel, tristique ac, condimentum non, tellus. 
In \cref{chap:back} curabitur nulla purus, feugiat id, elementum in, lobortis quis, pede.
In \cref{chap:architecture} consequat ligula nec tortor. Integer eget sem. Ut vitae enim eu est vehicula gravida.
\Cref{chap:implement} morbi egestas, urna non consequat tempus, nunc arcu mollis enim, eu aliquam erat nulla non nibh in \cref{chap:evaluation}.
\Cref{chap:conclusion} suspendisse dolor nisl, ultrices at, eleifend vel, consequat at, dolor.