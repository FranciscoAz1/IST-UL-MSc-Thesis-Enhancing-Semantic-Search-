% #############################################################################
% This is Chapter 3
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{State of the Art}
\label{chap:sota-agentic-ai}
\cleardoublepage

This chapter surveys \ac{AAI}, language-model driven agents that plan, use tools, and manage memory, to improve retrieval and answer quality. We focus on methods that (i) reason and decompose tasks, (ii) call external tools and data sources, and (iii) maintain working åand long-term memory. We also connect these capabilities to \ac{RAG} pipelines that must respect organizational structure (folders, metadata) and access control.

\section{From Prompting to Agentic Behavior}
\textbf{Prompt engineering.} Well-designed instructions can control output format, tone, and constraints, and can inject short domain context. History (dialog state) may be summarized and re-provided as context; however, prompting alone does not guarantee factuality or stable tool use.

\textbf{In-context learning vs.\ fine-tuning.} Few-shot prompts adapt behavior without training, at the cost of input tokens and brittle generalization. Fine-tuning bakes patterns into model weights, reducing prompt length and latency, but requires curated data, cost, and re-deployment.
Add an example here of few-shot prompt

\section{Reasoning and Planning}
\textbf{Chain-of-Thought (CoT).} CoT prompting was introduced to address cases where the mapping from input $x$ to output $y$ is non-trivial, such as mathematical reasoning or multi-step logical inference. The key idea is to introduce a sequence of intermediate reasoning steps $z_{1}, \dots, z_{n}$ that bridge $x$ and $y$, where each $z_{i}$ represents a coherent language fragment (e.g., an intermediate equation or sub-derivation). Formally, each step is generated sequentially as $z_{i} \sim p_{\text{CoT}}(z_{i}\,|\,x, z_{1},\dots,z_{i-1})$, followed by $y \sim p_{\text{CoT}}(y\,|\,x, z_{1},\dots,z_{n})$. In practice, the entire reasoning trace and final answer $[z_{1}, \dots, z_{n}, y]$ is sampled as a continuous language sequence, with no fixed granularity for $z_{i}$—it may correspond to a phrase, a sentence, or even a full paragraph.

An extension, \emph{Self-Consistency with CoT} (CoT-SC), improves reliability by sampling $k$ independent reasoning chains $[z^{(i)}_{1}, \dots, z^{(i)}_{n}, y^{(i)}] \sim p_{\text{CoT}}(z, y\,|\,x)$ for $i=1,\dots,k$, and returning the most frequent output $\hat{y} = \arg\max_{y}\#\{i \mid y^{(i)} = y\}$. This ensemble approach mitigates the brittleness of a single sampled chain, since multiple distinct reasoning paths can converge to the same correct answer. CoT-SC is especially effective in domains where diverse thought processes are valid (e.g., different proofs of the same theorem). However, within each individual chain, there is no branching or exploration of alternative intermediate steps, and the majority-vote heuristic is mainly effective in restricted output spaces such as multiple-choice QA. These limitations motivated subsequent frameworks like Tree-of-Thoughts (ToT), which add structured search and backtracking over reasoning paths.

\textbf{Tree-of-Thoughts (ToT).} ToT generalizes CoT by treating intermediate reasoning steps as \emph{thoughts} that branch into a search tree. Instead of committing to a single linear chain, the model can decompose a problem into sub-goals, generate multiple candidate thoughts at each step, and heuristically evaluate the resulting states. Common evaluation criteria include task-specific scoring functions, likelihood of correctness, or external verification signals. The agent then applies a search algorithm—such as depth-first search, breadth-first search, or best-first search—to explore promising branches. Crucially, ToT enables backtracking: when a branch leads to a dead end, the system can return to a prior state and reconsider alternative thoughts, incorporating knowledge gained from failed attempts. This deliberative process allows LLMs to approximate planning and problem solving more effectively than linear CoT, particularly under uncertainty or when multi-step reasoning requires revisiting prior decisions.


\textbf{Reasoning \emph{and} Acting (ReAct).} ReAct interleaves thoughts with actions (tool calls, web/db queries) and observations. This closes the loop between planning and evidence gathering, reducing hallucinations on knowledge tasks. Compared to CoT it reduced hallucinations from 14\% to 6\%

\section{Tool Use and Orchestration}
\textbf{Self-taught tool use.} \emph{Toolformer} trains models to decide when and how to call APIs, improving arithmetic, lookup, and translation without heavy supervision.

\textbf{API-faithful calling.} \emph{Gorilla} fine-tunes LLMs with Retrieval-Aware Training (RAT) so the agent learns to consult evolving API docs at inference and reduces hallucinated calls.

\textbf{Model orchestration.} \emph{HuggingGPT} treats the LLM as a controller that plans subtasks and routes them to expert models; \emph{AutoGen} generalizes this to multi-agent conversations (LLM↔LLM↔Human↔Tools), useful for complex retrieval workflows (decomposition, retrieval, verification).

\section{Memory for Agents}
\textbf{Working vs.\ long-term memory.} Practical agents separate short context (scratchpad), episodic logs (events, prior answers), and semantic memory (facts, entities). \emph{MemGPT} formalizes tiered memory management beyond context windows.

\textbf{Reflective control.} \emph{Reflexion} adds a feedback loop: the agent critiques past trials and stores distilled lessons in memory, improving subsequent decisions without weight updates.

\section{Agentic RAG for Enterprise Retrieval}
\textbf{Problem.} Enterprise content lives in nested folders with metadata and ACLs. Pure dense retrieval over flat chunks ignores hierarchy, provenance, and permissions.

\textbf{Plan–Retrieve–Verify loop.} An effective agentic RAG pipeline:
\begin{enumerate}\itemsep2pt
    \item \textbf{Plan.} Parse the question, identify entities/fields, and choose tools (vector DB, metadata filter, file system API).
    \item \textbf{Hierarchical retrieval.} First select candidate folders/entities (sparse or metadata filters), then retrieve dense chunks within those scopes; rerank with cross-encoders; enforce ACLs.
    \item \textbf{Self-reflection.} If evidence is thin or conflicting, reformulate the query, expand terms, or traverse adjacent folders/linked entities (multi-hop).
    \item \textbf{Generate with grounding.} Compile an answer with citations to specific files/paths and timestamps; add uncertainty flags if evidence is weak.
\end{enumerate}

\textbf{Techniques.} Hierarchical retrieval (folder/entity$\to$document$\to$chunk) reduces noise and latency. Graph-guided retrieval (\emph{GraphRAG}) adds edges between entities/sections to improve multi-hop reasoning. Adaptive retrieval with \emph{Self-RAG} lets the model decide \emph{when} to retrieve and to critique its own generations, improving factuality and citation behavior. These patterns combine naturally with ReAct: thoughts trigger folder-scoped searches; observations update the plan.

\section{Evaluation}
Agent performance should be measured beyond answer text:
\begin{itemize}\itemsep2pt
    \item \textbf{Task success on interactive environments:} \emph{AgentBench}, \emph{WebArena}, \emph{Mind2Web}, \emph{OSWorld}, and \emph{BrowserGym} cover planning, tool use, and real web/computer operations.
    \item \textbf{Retrieval quality:} precision/recall@k, MRR/nDCG on document IDs (folder-aware); groundedness/faithfulness (LLM- or rule-based); citation accuracy to specific file paths and versions.
    \item \textbf{Latency and cost:} hops, tool calls, tokens.
    \item \textbf{Robustness and safety:} resistance to prompt/indirect-prompt injection and unsafe actions (see below).
\end{itemize}

\section{Safety and Governance}
Agents amplify risks because they act. Relevant threats include indirect prompt injection from retrieved documents or web pages, API misuse, and unsafe GUI/file operations. Use \emph{deny-by-default} tool policies, allow-lists, strict sandboxing, content sanitization before feeding to the model, and runtime guards (e.g., verification and user confirmation for destructive actions). Evaluate with dedicated safety benchmarks and industry guidance (e.g., OWASP LLM01) and log all actions for auditability.

\section{Takeaways for This Thesis}
For enterprise semantic search, \ac{AAI} adds:
(i) \textbf{planning} to decompose queries and choose retrieval tools;
(ii) \textbf{hierarchical, metadata-aware retrieval} aligned with folders and ACLs;
(iii) \textbf{reflection} to re-query when evidence is weak;
(iv) \textbf{grounded generation} with verifiable citations. 
These capabilities directly target recall and precision in scattered document stores while preserving security and governance.
