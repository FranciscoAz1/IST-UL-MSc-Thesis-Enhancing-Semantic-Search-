% #############################################################################
% This is Appendix B
% !TEX root = ../main.tex
% #############################################################################
% Plain text listings style (no syntax highlighting)
\lstdefinelanguage{plaintext}{}
\lstset{
  language=plaintext,
  breaklines=true,
  basicstyle=\ttfamily\small,
  columns=fullflexible,
  keepspaces=true,
  breakatwhitespace=true,
  showstringspaces=false,
  keywordstyle=,
  commentstyle=,
  stringstyle=,
  % Color brace-delimited placeholders and keep braces visible
  moredelim=**[s][\color{blue}]{\{}{\}}
}
\chapter{Prompts}
\label{chapter:appendixB}

This appendix contains the prompts used in the various stages of the project, including metadata extraction, question generation, and agent interaction. Each prompt is designed to guide the \gls{LLM} in performing specific tasks effectively.

\section{Metadata Extraction Prompt}\label{sec:metadata-extraction-prompt}\label{prompt:metadata-extraction}
\subsection{Prompt Constants}
\begin{itemize}
    \item \texttt{DEFAULT\_TUPLE\_DELIMITER}: <|>
    \item \texttt{DEFAULT\_RECORD\_DELIMITER}: \#\#
    \item \texttt{DEFAULT\_COMPLETION\_DELIMITER}: <|COMPLETE|>
    \item \texttt{DEFAULT\_ENTITY\_TYPES}: organization, person, location, event
\end{itemize}

\subsection{Entity Extraction Prompt}\label{prompt:entity-extraction}
\begin{lstlisting}
Goal-
Given a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.

-Steps-
1. Identify all entities. For each identified entity, extract the following information:
- entity_name: Name of the entity, use same language as input text. If English, capitalized the name.
- entity_type: One of the following types: [{entity_types}]
- entity_description: Comprehensive description of the entity's attributes and activities
Format each entity as ("entity"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>

2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.
For each pair of related entities, extract the following information:
- source_entity: name of the source entity, as identified in step 1
- target_entity: name of the target entity, as identified in step 1
- relationship_description: explanation as to why you think the source entity and the target entity are related to each other
- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity
- relationship_keywords: one or more high-level key words that summarize the overarching nature of the relationship, focusing on concepts or themes rather than specific details
Format each relationship as ("relationship"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_keywords>{tuple_delimiter}<relationship_strength>

3. Identify high-level key words that summarize the main concepts, themes, or topics of the entire text. These should capture the overarching ideas present in the document.
Format the content-level key words as ("content_keywords"{tuple_delimiter}<high_level_keywords>)

4. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **{record_delimiter}** as the list delimiter.

5. When finished, output {completion_delimiter}

###################### 
-Examples-
###################### 
Entity_types: [type1, type2, ...]
Text:
<example input text>
################
Output:
("entity"<|>"Name"<|>"Type"<|>"Description")##
("relationship"<|>"Source"<|>"Target"<|>"Description"<|>"Keywords"<|>Strength)##
("content_keywords"<|>"keywords"){completion_delimiter}

-Real Data-
###################### 
Entity_types: {entity_types} 
Text: {input_text} 
###################### 
Output:
\end{lstlisting}

\subsection{Summarize Entity Descriptions Prompt}\label{prompt:summarize-entity-descriptions}
\begin{lstlisting}
You are a helpful assistant responsible for generating a comprehensive summary of the data provided below.
Given one or two entities, and a list of descriptions, all related to the same entity or group of entities.
Please concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.
If the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.
Make sure it is written in third person, and include the entity names so we the have full context.

#######
Entities: {entity_name}
Description List: {description_list}
#######
Output:
\end{lstlisting}

\subsection{Missing entities detection}\label{prompt:missing-entities}
\begin{lstlisting}
     It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.
\end{lstlisting}

\subsection{Continue Extraction Prompts}\label{prompt:continue-extraction}
\begin{lstlisting}
MANY entities were missed in the last extraction.
After summarizing with all the information previously extracted, compared to the original text, it was noticed that the following information was mainly omitted:
{omit}

The types of entities that need to be added can be obtained from Entity_types,
or you can add them yourself.

Entity_types: {entity_types}

Add them below using the same format:
\end{lstlisting}

\subsection{If Loop Extraction Prompt}\label{prompt:if-loop-extraction}
\begin{lstlisting}
It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.
\end{lstlisting}

\subsection{MiniRAG Query to Keyword Prompt}\label{prompt:minirag-query-keyword}
\begin{lstlisting}
---Role---

You are a helpful assistant tasked with identifying both answer-type and low-level keywords in the user's query.

---Goal---

Given the query, list both answer-type and low-level keywords.
answer_type_keywords focus on the type of the answer to the certain query, while low-level keywords focus on specific entities, details, or concrete terms.
The answer_type_keywords must be selected from Answer type pool.
This pool is in the form of a dictionary, where the key represents the Type you should choose from and the value represents the example samples.

---Instructions---

- Output the keywords in JSON format.
- The JSON should have three keys:
  - "answer_type_keywords" for the types of the answer. In this list, the types with the highest likelihood should be placed at the forefront. No more than 3.
  - "entities_from_query" for specific entities or details. It must be extracted from the query.
######################
-Examples-
######################
[Example structure omitted for brevity.]
-Real Data-
######################
Query: {query}
Answer type pool:{TYPE_POOL}
######################
Output:
\end{lstlisting}
\subsubsection{Example structure:}
\begin{lstlisting}
######################
-Examples-
######################
Query: <example query>
Answer type pool: { ... }
################
Output:
{
  "answer_type_keywords": ["TYPE1", "TYPE2"],
  "entities_from_query": ["Entity1", "Entity2"]
}
\end{lstlisting}

\subsection{Fail Response Prompt}\label{prompt:fail-response}
\begin{lstlisting}
Sorry, I'm not able to provide an answer to that question.
\end{lstlisting}

\subsection{RAG Response Prompt}\label{prompt:rag-response}
\begin{lstlisting}

You are a helpful assistant responding to questions about data in the tables provided.


Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.
If you don't know the answer, just say so. Do not make anything up.
Do not include information where the supporting evidence for it is not provided.


{response_type}


{context_data}

Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.
\end{lstlisting}

\section{Agent Instruction Prompt}\label{sec:agent-instruction-prompt}\label{prompt:agent-instruction}
\begin{lstlisting}
You are a helpful assistant with access to a Weaviate database via tools.

Goal:

Instructions:
\end{lstlisting}
\begin{lstlisting}
You are a helpful assistant with access to a Weaviate database via tools.

Goal:
- Retrieve relevant information and provide direct, concise answers in Portuguese.
- Always ground answers in retrieved content and cite source file paths; include a short quote when helpful.

Instructions:
- When you need data, request the 'weaviate-query' tool.
- Do not ask for clarification; do your best with the information available.
- Parse tool results to extract the key text and file_path.
- When you know the final answer, prefix it exactly with: "FINAL ANSWER: "
\end{lstlisting}

\section{Algorithm: Naive Weaviate Hybrid + grouped\_task RAG}\label{alg:naive-weaviate-hybrid}
\begin{algorithm}[H]
  \DontPrintSemicolon
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \Input{\begin{tabular}{@{}l@{}}
    User query $q$; Weaviate collection $rag$ (e.g., ``Dataset'');\\
    Hybrid weight $\alpha=0.7$; top-$k=3$; target\_vector~=~\texttt{"text\_vector"};\\
    Portuguese prefix $P$ = ``Responda de forma breve e objetiva em portuguÃªs (pt-PT): ''
  \end{tabular}}
  \Output{\begin{tabular}{@{}l@{}}
    Answer text $a$; retrieved list $R$ of tuples (\texttt{file\_path}, distance)
  \end{tabular}}
  \BlankLine
  $grouped\_task \leftarrow P \Vert q$ \tcp*{Enforce pt-PT and brevity}
  $result \leftarrow rag.generate.hybrid($
    $query{=}q,$ $alpha{=}\alpha,$ $limit{=}k,$\\
    $target\_vector{=}$\texttt{"text\_vector"}, $grouped\_task{=}grouped\_task,$\\
    $return\_metadata{=}$\texttt{MetadataQuery(distance=True)}$)$
  	cp*{Hybrid retrieval + grouped generation}
  \BlankLine
  	cp{Extract grouped answer; if empty, fallback to concatenated retrieved texts}
  $gen \leftarrow result.generative$; $a \leftarrow$ \texttt{None}\;
  \If{$gen \neq \varnothing$ \textbf{and} $gen.text$ exists}{
    $a \leftarrow gen.text$
  }
  \Else{
    $T \leftarrow$ first 2 retrieved object texts from $result.objects$ (truncate as needed)\;
    $a \leftarrow$ join($T$, ``\textbackslash n---\textbackslash n'')\; 
  }
  \BlankLine
  	cp{Collect provenance and scores}
  $R \leftarrow [\; (obj.properties[\texttt{"file\_path"}], obj.metadata.distance) \;\mid\; obj \in result.objects\; ]$\;
  \BlankLine
  \Return $a, R$\;
  \caption{Naive RAG over Weaviate using Hybrid($\alpha{=}0.7$) retrieval and grouped\_task generation}
\end{algorithm}